# Система обработки данных поставщиков

## Обзор
Этот проект реализует  систему обработки и управления данными поставщиков. Используются контейнеры Docker для оркестрации базы данных PostgreSQL, сервиса обработки данных и веб-интерфейса. Система автоматизирует извлечение, обработку и хранение данных с запланированными обновлениями каждые 6 часов. Разработана с учетом масштабируемости, поддерживает нескольких поставщиков и предоставляет RESTful API для управления файлами.

## Функционал

### Обработка данных
- **Извлечение данных**: Получает необработанные данные из API, преобразует их в единый Excel-файл (`unified.xlsx`).
- **Анализ изменений**: Сравнивает текущий `unified.xlsx` с файлом предыдущего дня для выявления добавленных, удаленных или измененных записей.
- **Генерация отчета**: Создает файл `report.xlsx` с отдельными листами для изменений при обнаружении различий.
- **Управление хранением**: Сохраняет файлы в структуре директорий (`/app/storage/[поставщик]/[дата]/`)
- **Автоматизация**: Выполняет задачи обработки данных каждые 6 часов с использованием библиотеки Python `schedule`, с обработкой ошибок и ведением логов.

### Управление базой данных
- **Бэкенд**: Использует PostgreSQL 13 для хранения метаданных и путей к файлам в таблице `file_records`.
- **Схема**: Включает столбцы `id` (SERIAL PRIMARY KEY), `date` (DATE), `current_unified_path` (TEXT), `previous_unified_path` (TEXT), `report_path` (TEXT) и `supplier_name` (TEXT), с составным уникальным ограничением на `date` и `supplier_name` 

### Веб-интерфейс
- **Эндпоинт**: Предоставляет веб-сервер на основе FastAPI на порту 8000.
- **Функции**: Отображает раскрывающийся список поставщиков (в настоящее время только Altacera) с ссылками для скачивания последних файлов `unified.xlsx` и `report.xlsx` за последние два дня.
- **API**: Предоставляет эндпоинт `/download/{file_path}` для получения файлов, возвращая код 404, если файл недоступен.

### Развертывание
- **Оркестрация**: Управляется через Docker Compose с сервисами `db` (PostgreSQL), `processor` (обработка данных) и `web` (веб-сервер).
- **Конфигурация**: Зависит от `.env` для учетных данных базы данных и `.env.suppliers` для настроек, специфичных для поставщиков (например, URL API).
- **Сохранение**: Использует тома Docker (`db_data`) для хранения базы данных и тома хоста (`./storage`) для сохранения файлов.

## Предварительные требования
- Установленные Docker и Docker Compose (последние стабильные версии).
- Python 3.9+ с зависимостями, указанными в `processor/requirements.txt` и `web/requirements.txt` 


## Установка
1. Склонируйте репозиторий
2. Настройте файлы окружения:
- Создайте `.env` с `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` и `DATABASE_URL`.
- Создайте `.env.suppliers` с `SUPPLIER_URL`.
- запустите контейнеры

## Конфигурация
- **.env**: Определяет параметры подключения к базе данных.
- **.env.suppliers**: Указывает эндпоинты API поставщиков.
- При необходимости измените сопоставление портов или путей в `docker-compose.yml`.

## Обслуживание
- **Очистка данных**: Реализуйте cron-задание или скрипт для удаления файлов старше 365 дней из `/app/storage`.
- **Мониторинг**: Регулярно проверяйте логи на наличие проблем с подключением или сбоями обработки.
- **Резервное копирование**: Периодически создавайте резервные копии тома `db_data` для предотвращения потери данных.

## Разработка

- **Зависимости**: Обновляйте файлы `requirements.txt` при добавлении новых библиотек.


### Примечания для разработчиков
- Система предполагает стабильное подключение к API/FTP/другому ресурсу от поставщика. Рекомендуется реализовать логику повтора запросов при необходимости повышения надежности.
- Схема таблицы `file_records` поддерживает расширение; рассмотрите добавление индексов для `supplier_name`, если производительность запросов снизится при больших объемах данных.
- Исключите файлы `.env` из контроля версий (добавьте в `.gitignore`) для защиты конфиденциальных данных.
